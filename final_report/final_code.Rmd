---
title: "final code"
author: "Gege Gui"
---

```{r}
# Slack group (Shannon)
packages = c("devtools", "stringr", "ggplot2", "tm", "tidytext", "dplyr", "topicmodels")

for (i in packages){
  if(!require(i,character.only = T,quietly=T,warn.conflicts = F)){
    install.packages(i, repos = "http://cran.us.r-project.org")
  }
  require(i,character.only = T,quietly=T,warn.conflicts = F)
}

devtools::install_github("ropensci/rplos")

load("final_data.RData")
```

```{r}
library("rplos")
library("stringr")
library("ggplot2")
library("tm")
library("tidytext")
library("dplyr")
library("topicmodels")
```

## PLoS R package

```{r}
# Get only full article DOIs
id = searchplos("abstract:statistics", fl='id, publication_date', fq='doc_type:full', sort = 'publication_date desc', start=0)

dic = c("linear regression","Lasso","ridge regression","linear discriminant analysis","bootstrap","maximum likelihood","MCMC","neural network","support vector machine","clustering","principal component","independent component","random forest","graphical model", "Kaplan", "Cox proportional")

# l = list()
# for (i in 1:length(dic)){
#   id = searchplos(paste("abstract:", dic[i]), fl='id, publication_date', sort = 'publication_date desc', start=0)
#   a = id$meta$numFound
#   id = searchplos(paste("abstract:", dic[i]), fl='id, publication_date', sort = 'publication_date asc', start=0, limit = a)
#   l[[i]] = id$data$publication_date
# }
```

```{r}
getdate = function(strg){
  library("stringr")
  d = str_split(strg, pattern = fixed("T"), simplify = T)[1]
  return(d)
}

countmonth = function(v, name){
  d = sapply(v, getdate)
  s = str_split(d, pattern = fixed("-"), simplify = T)[, 1:2]
  out = as.data.frame(rep(0, 10 * 12))
  rownames(out) = paste(as.vector(sapply(2007:2016, function(x){return(rep(x, 12))})), "-", rep(1:12, 10), sep = "")
  colnames(out) = name
  s = matrix(as.numeric(s), nrow = nrow(s))
  a = matrix(rep(0, 10*12), nrow = 10)
  for (i in 2007:2016){
    for (j in 1:12){
      a[i - 2006, j] = sum(s[,1] == i & s[, 2] == j)
    }
  }
  out[,1] = as.vector(t(a))
  return(out)
}

countyear = function(v, name){
  d = sapply(v, getdate)
  s = str_split(d, pattern = fixed("-"), simplify = T)[, 1]
  out = as.data.frame(rep(0, 10))
  rownames(out) = 2007:2016
  colnames(out) = name
  s = as.numeric(s)
  for (i in 2007:2016){
      out[i - 2006,1] = sum(s == i)
    }
  return(out)
}

count_month = countmonth(l[[1]], dic[1])
for (i in 2:length(l)){
  count_month = cbind(count_month, countmonth(l[[i]], dic[i]))
}

count_year = countyear(l[[1]], dic[1])
for (i in 2:length(l)){
  count_year = cbind(count_year, countyear(l[[i]], dic[i]))
}
```

Plot total count

```{r}
s = rep(NA, length(dic))
for (i in 1:length(l)){
  s[i] = length(l[[i]])
}

dic2 = dic[order(s)]
s2 = sort(s)
df = data.frame(dic2, s2)

p = ggplot(data=df, aes(x= reorder(dic2, -s2), y=s2)) + geom_bar(stat="identity")
p + coord_flip() + labs(x = "count in paper 2007 - 2016", y = "statistical methods", fill = "statistical methods") + geom_text(aes(label = s2), size = 3,  hjust = -0.5, position = position_dodge(width = 1)) + ylim(0, max(s) + 1000) + guides(fill=FALSE)
```

Plot trend over time

Plot those with more than 1000 count.

By year

```{r}
name_list = as.character(df[df$s2 >= 1000, 1])
plot_year = count_year[,colnames(count_year) %in% name_list]
date = 2007:2016
ggyear = function(i) {
  out = paste("+ geom_line(aes(y = plot_year[,", i, "],colour = colnames(plot_year)[",  i, "]))", sep = "")
  return(out)
}
eval(parse(text = paste("ggplot(data=plot_year, aes(date))", paste((sapply(1:10, ggyear)), collapse = "")))) + labs(title="Year count for count > 1000", x ="Time", y = "Count", colour = "Statistical method")

plot_year_prob = sweep(plot_year,2,colSums(plot_year), "/")
ggyear_prob = function(i) {
  out = paste("+ geom_line(aes(y = plot_year_prob[,", i, "],colour = colnames(plot_year_prob)[",  i, "]))", sep = "")
  return(out)
}
eval(parse(text = paste("ggplot(data=plot_year_prob, aes(date))", paste((sapply(1:10, ggyear_prob)), collapse = "")))) + labs(title="Year count probability for count > 1000", x ="Time", y = "Probability in year", colour = "Statistical method")
```

Normalizing by count every year

```{r}
plot_year_norm = sweep(plot_year,1,rowSums(plot_year), "/")
ggyear_norm = function(i) {
  out = paste("+ geom_line(aes(y = plot_year_norm[,", i, "],colour = colnames(plot_year_norm)[",  i, "]), size = 1.2)", sep = "")
  return(out)
}
eval(parse(text = paste("ggplot(data=plot_year_norm, aes(date))", paste((sapply(1:10, ggyear_norm)), collapse = "")))) + labs(title="Year count probability for count > 1000", x ="Time", y = "Probability in year", colour = "Statistical method")
```

By month

```{r}
plot_month = count_month[,colnames(count_month) %in% name_list]
date_m = 1:120
ggmonth = function(i) {
  out = paste("+ geom_line(aes(y = plot_month[,", i, "],colour = colnames(plot_month)[",  i, "]))", sep = "")
  return(out)
}
eval(parse(text = paste("ggplot(data=plot_month, aes(date_m))", paste((sapply(1:10, ggmonth)), collapse = "")))) + labs(title="Month count for count > 1000", x ="Time", y = "Count", colour = "Statistical method")

plot_month_prob = sweep(plot_month,2,colSums(plot_month), "/")
ggmonth_prob = function(i) {
  out = paste("+ geom_line(aes(y = plot_month_prob[,", i, "],colour = colnames(plot_month_prob)[",  i, "]))", sep = "")
  return(out)
}
eval(parse(text = paste("ggplot(data=plot_month_prob, aes(date_m))", paste((sapply(1:10, ggmonth_prob)), collapse = "")))) + labs(title="month count probability for count > 1000", x ="Time", y = "Probability in month", colour = "Statistical methods")
```

Normalizing by count every month

```{r}
plot_month_norm = sweep(plot_month,1,rowSums(plot_month), "/")
ggmonth_norm = function(i) {
  out = paste("+ geom_line(aes(y = plot_month_norm[,", i, "],colour = colnames(plot_month_norm)[",  i, "]))", sep = "")
  # , size = 2
  return(out)
}
eval(parse(text = paste("ggplot(data=plot_month_norm, aes(date_m))", paste((sapply(1:10, ggmonth_norm)), collapse = "")))) + labs(title="Month count probability for count > 1000", x ="Time", y = "Probability in month", colour = "Statistical methods")
```


## Topic model

```{r}
# dsource = DirSource(directory = "/Users/gege/Downloads/PLoS_Curr")
# dictionary = scan("/Users/gege/Dropbox/graduate/DataScience/project/Data/words.txt", character(), quote = "")
# file = VCorpus(dsource, readerControl = list(reader = readPlain)) 
origfile = file
```

Remove numbers

```{r}
for (i in 1:length(file)){
  file[[i]] = removeNumbers(file[[i]])
}
```

From VCorpus to dataframe

```{r}
tidy_file = tidy(file)
tidyfile = tidy_file[,c("id", "text")]
```

Keep words in this list of English words: 

Unnest the tokens, remove the stopwords.

```{r}
fileunnest = tidyfile %>% unnest_tokens(word, text) 
file_words = anti_join(fileunnest, stop_words) 
```

Remove the 20 most frequent words.

```{r}
file_count = as.vector(table(file_words[, colnames(file_words) %in% "word"]))
file_count2 = rownames(as.matrix(table(file_words[, colnames(file_words) %in% "word"])))
word_freq = file_count2[order(file_count, decreasing = T)][1:20]

wholevol = unique(fileunnest$word)
file_word = file_words[file_words$word %in% dictionary, ]
antistopword = unique(file_word$word)
newstopword = union(setdiff(wholevol, antistopword), word_freq)
new_stop = as.data.frame(t(newstopword))
colnames(new_stop) = "word"
f_word = anti_join(as.data.frame(fileunnest), new_stop)
```

Some stopwords from model fitting

```{r}
othersw = c("documentclassptarticle", "usepackageamsbsy", "usepackageamsfonts", "usepackageamsmath","usepackageamssymb", "usepackagemathrsfs","usepackagepmc","usepackagewasysym", "begindocument")
newstopword = c(newstopword, othersw)
```

Word in file count

```{r}
filefreq = f_word %>%
  group_by(id) %>%
  count(word) %>%
  filter(n > 5)
```

```{r}
getmethod = function(f){
  out = f
  lselect = rep(TRUE, length(f))
  for (j in 1:length(f)){
    text = f[[j]]$content
    sent_wc = rep(NA, length(text))
    method = rep(0, length(text))
    result = method
    
    for (i in 1:length(text)){
      unnest = unlist(str_split(removePunctuation(text[i]), pattern = " ")) 
      words = unnest[unnest != ""]
      sent_wc[i] = length(words)
      method[i] = sum(words %in% c("Method", "Methods", "Methodology"))
      result[i] = sum(words %in% c("Results", "Discussion", "Supporting"))
    }
    
    start = which(method == 1 & sent_wc < 4)[1]
    end = which(result == 1 & sent_wc < 4)[1]
    
    if ((is.na(start) | is.na(end)) | (start >= end)){
      lselect[j] = FALSE
    } else{
    index = which(sent_wc > 1) 
    ind = index[index > start & index < end]
    out[[j]]$content = text[ind]
    }
  }
  return(out[lselect])
}

method_file = getmethod(file)
```

```{r}
t_file = DocumentTermMatrix(method_file, control = list(removePunctuation = TRUE, wordLengths = c(3, 19),  removeNumbers = TRUE, stopwords = c(stopwords("english"), newstopword))) 
# stemming = TRUE,

rowTotals = apply(t_file, 1, sum) #Find the sum of words in each Document
t_file = t_file[rowTotals> 0, ] 

topic = 5
# lda = LDA(t_file, topic)
lda_inf = posterior(lda)


article = lda_inf[[2]]
term = lda_inf[[1]]
term_pos = matrix(rep(NA, 20 * nrow(term)), nrow = nrow(term))

n = 30
wo = as.data.frame(matrix(rep(NA, topic * n), ncol = topic))
colnames(wo) = 1:5 
rownames(wo) = paste(rep("word", n), 1:n)
name = colnames(term)
for (i in 1:nrow(term)){
  dat = term[i, ]
  or = order(dat, decreasing = T)
  wo[,i] = name[or[1:n]]
}

to = apply(article, 1, which.max)
to.prob = apply(article, 1, max)
print.data.frame(wo)
```

```{r}
mfile = method_file
a = matrix(rep(0, length(dic) * length(mfile)), nrow = length(mfile))
for (i in 1:length(mfile)){
  for (j in 1:length(dic)){
    a[i, j] = sum(grep(dic[j], mfile[[i]]$content))
  }
}

fileind = 1:length(mfile) * (rowSums(a) > 0)
fileind = fileind[fileind > 0]
filedic = dic[colSums(a) > 0]

b = list()
for (i in 1:length(fileind)){
  b[[i]] = c("s")
  for (j in 1:length(filedic)){
    ind = fileind[[i]]
    kw = sum(grep(filedic[j], mfile[[ind]]$content))
    if (kw > 0){
      b[[i]] = c(b[[i]], filedic[j])
    }
  }
  b[[i]] = b[[i]][2:length(b[[i]])]
}
```

```{r}
filetopic = to[fileind]
tp = c("laboratory science", "community survey", "natural disaster", "infectious disease", "population network")
ftopic = tp[filetopic]

topic_method = as.data.frame(matrix(rep(0, topic * length(filedic) * 3), ncol = 3))
colnames(topic_method) = c("topic", "method", "count")
topic_method[,1] = as.vector(sapply(tp, function(x){return(rep(x, length(filedic)))}))
for (i in 1:topic){
  name = tp[i]
  dat = c()
  for (k in 1:length(b)){
    if (filetopic[k] == i)
      dat = c(dat, b[[k]])
  }
  out = as.data.frame(table(dat))
  colnames(out) = c("method", "count")
  test = as.data.frame(as.matrix(filedic), ncol = 1)
  colnames(test) = "method"
  out = merge(test, out, by="method", all=TRUE)
  out[is.na(out)] = 0
  topic_method[((i - 1) * length(filedic) + 1):(i * length(filedic)), 2] = as.vector(out[,1])
  topic_method[((i - 1) * length(filedic) + 1):(i * length(filedic)), 3] = as.vector(out[,2])
}

pl = ggplot(data = topic_method, aes(x= topic, y=count, fill = method)) + geom_bar(stat="identity")
plotp1 = pl + labs(x = "5 topics", y = "statistical method count", fill = "statistical methods") 
plotp1
```